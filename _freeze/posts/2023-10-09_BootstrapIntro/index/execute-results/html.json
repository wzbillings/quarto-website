{
  "hash": "70707c7ae7413c018a646888f98865de",
  "result": {
    "markdown": "---\ntitle: \"Intro to Bootstrap CIs\"\nauthor: \"Zane Billings\"\ndate: \"2023-10-09\"\ndescription: |\n  One of my lab mates wanted to calculate bootstrap CIs for a project, which\n  is something I know how to do. So I wanted to write a basic tutorial on\n  bootstrap confidence intervals.\nlicense: \"CC BY-SA\"\ndraft: false\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# ggplot2 theme setup\nlibrary(ggplot2)\nggplot2::theme_set(\n\tggplot2::theme_minimal() +\n\t\tggplot2::theme(\n\t\t\tplot.background = ggplot2::element_rect(\n\t\t\t\tfill = \"white\", color = \"white\"\n\t\t\t),\n\t\t\taxis.text = ggplot2::element_text(size = 12, color = \"black\"),\n\t\t\taxis.title = ggplot2::element_text(size = 22),\n\t\t\tplot.subtitle = ggplot2::element_text(\n\t\t\t\tsize = 16, hjust = 0, margin = ggplot2::margin(b = 2)\n\t\t\t),\n\t\t\tplot.title = ggplot2::element_text(\n\t\t\t\tsize = 19, hjust = 0, margin = ggplot2::margin(b = 2, l = 2)\n\t\t\t),\n\t\t\tplot.caption = ggplot2::element_text(size = 14),\n\t\t\tstrip.text = ggplot2::element_text(\n\t\t\t\tsize = 16, hjust = 0.5, margin = ggplot2::margin(b = 2, t = 2)\n\t\t\t),\n\t\t\tpanel.spacing = ggplot2::unit(2, \"lines\"),\n\t\t\tlegend.position = \"bottom\",\n\t\t\tlegend.text = ggplot2::element_text(size = 16, color = \"black\"),\n\t\t\tlegend.title = ggplot2::element_text(size = 18, color = \"black\"),\n\t\t\tplot.margin = ggplot2::margin(t = 6, r = 6, b = 6, l = 6)\n\t\t)\n)\n```\n:::\n\n\nIn this blog post, I'm going to go over a short example of using the\nnonparametric bootstrap to construct confidence intervals for arbitrary\nstatistics. Exact and asymptotic limits are all great, but unfortunately they\nhave to exist before you can calculate them, and these methods are often\nvery analytically difficult (requiring, e.g., Taylor series analysis). We\ncan often trade off computational power for analytical problem solving using\nthe bootstrap method to construct pretty good confidence intervals instead.\n\nI'll start by going over what I think is the most intuitive approach for\nbootstrap CIs, the percentile method. This method has some limitations though,\nso I'll talk about the BCa adjustment which can produce better results, and\nI'll talk about how to get these CIs with the `boot` package in `R`.\n\n## Example problem setup\n\nFor an example, we'll make some simulated data that's similar to the situation\nwhere we actually need to use a bootstrap CI in my lab group's research. We'll\nconsider a fairly simple example: in a study sample of size $n$, $n_t$ people\nget a vaccine and $n_p$ people get a placebo. They are followed up for an\nappropriate amount of time (or challenge with virus, your choice), and we\nrecord which individuals get infected and which do not. For this simulated\nexample, the effect we are interested in measuring is the vaccine effectiveness,\nwhich can be calculated from the risk ratio. That is,\n$$\\mathrm{VE} = 1 - \\mathrm{RR} = 1 - \\frac{\\text{risk in vaccine group}}{\\text{risk in placebo group}}.$$\nTo do this, we'll simulate infection data for both groups. If we want our\ntarget VE to be, say, $75\\%$, we want the risk ratio to be $25\\%$, and we\ncan set the two prevalences however we want, as long as they are sensible\nprevalences (between $0\\%$ and $100\\%$) and their ratio is $\\frac{1}{4}$. So\nfor ease of computation, let's say that the risk in the vaccine group is $10\\%$\nand the risk in the placebo group is $40\\%$. Let's simulate 100 patients where\n50 are in the placebo group and 50 are in the vaccine group.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(134122)\nsim_dat <- tibble::tibble(\n\t# Treatment is 0 for placebo, 1 for vaccinated\n\ttreatment = rep(c(0, 1), each = 50),\n\toutcome = rbinom(100, size = 1, prob = rep(c(0.4, 0.1), each = 50))\n)\n\ntable(\n\tsim_dat$treatment,\n\tsim_dat$outcome,\n\tdnn = c(\"treatment\", \"outcome\")\n) |>\n\taddmargins()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         outcome\ntreatment   0   1 Sum\n      0    27  23  50\n      1    43   7  50\n      Sum  70  30 100\n```\n:::\n:::\n\n\nIf we look at our table, we see that we get estimated risks of $23/50 = 46\\%$\nin the placebo group, and $7/50 = 14\\%$ in the vaccine group, giving us an\nobserved VE of $1 - 0.3043 \\approx 70\\%.$\n\nNow, we might want to construct a confidence interval for that, but we forgot\nall the different methods for that, no matter how many of them they taught us\nor how many times we covered it during epidemiology class. (Or if you're like\nme, you did an epidemiology PhD without any intro to epi classes and never\nreally learned…) So fortunately for us, nonparametric bootstrapping provides a\nreally convenient and flexible way to automatically get a CI, as long as we\nhave a decently fast computer.\n\n## Constructing resamples\n\nThe first step of computing a bootstrap CI is to construct the bootstrap\ndistribution. Bootstrapping refers to a specific type of **resampling** process\nthat's similar to cross-validation or leave-one-out methods. Call our entire\ndata set $D$. We construct a bootstrap resample $D_i$ ($i = 1, 2, \\ldots, B$ where $B$ is the number of bootstrap resamples we do) by **sampling with\nreplacement** $n$ records from $D$. This means that each resample can have the\nsame observation repeated multiple times, and does not have to include every\nobservation (in fact, we can use the bootstrap similarly to cross-validation\nfor model tuning by using the bootstrap resample as the analysis set and the\npoints not included in the resample as the assessment set). We resample in\nthis way specifically, because it leads to specific properties (under certain\nregularity conditions) which allow our confidence intervals to work correctly.\n(Math stuff omitted since I don't understand it too well and it's not so\nimportant.)\n\nWe could of course do this by hand.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3547512)\nB <- 199L\nres <- matrix(nrow = B, ncol = 4)\ncolnames(res) <- c(\"p_p\", \"p_t\", \"RR\", \"VE\")\nfor (i in 1:B) {\n\t# Sample the data indices that we should use for this sample\n\tidx <- sample.int(nrow(sim_dat), replace = TRUE)\n\tD_i <- sim_dat[idx, ]\n\t# Code to calculate the risk in the placebo group and the risk in the\n\t# treatment group\n\t# We could write this in a much more compact/efficient way, but I did it\n\t# this way for readability\n\tp_p <- D_i |>\n\t\tdplyr::filter(treatment == 0) |>\n\t\tdplyr::pull(outcome) |>\n\t\tmean()\n\tp_t <- D_i |>\n\t\tdplyr::filter(treatment == 1) |>\n\t\tdplyr::pull(outcome) |>\n\t\tmean()\n\tRR <- p_t / p_p\n\t\n\t# Store results in output matrix\n\tres[i, 1] <- p_p\n\tres[i, 2] <- p_t\n\tres[i, 3] <- RR\n\tres[i, 4] <- 1 - RR\n}\n\nres <- tibble::as_tibble(res)\nhead(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 4\n    p_p    p_t    RR    VE\n  <dbl>  <dbl> <dbl> <dbl>\n1 0.544 0.0698 0.128 0.872\n2 0.490 0.196  0.400 0.600\n3 0.46  0.12   0.261 0.739\n4 0.467 0.15   0.321 0.679\n5 0.533 0.145  0.273 0.727\n6 0.341 0.125  0.367 0.633\n```\n:::\n:::\n\n\nThis gives us a resampling or bootstrap distribution with 199 values for each\nof the calculated values ($p_p$, $p_t$, the $\\mathrm{RR}$, and the $\\mathrm{VE}$). We can look at those distributions. (I'll briefly explain why\nwe might choose 199 in a moment.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres |>\n\ttidyr::pivot_longer(cols = dplyr::everything()) |>\n\tggplot2::ggplot() +\n\tggplot2::aes(x = value) +\n\tggplot2::geom_histogram(\n\t\tbinwidth = 0.05,\n\t\tboundary = 0,\n\t\tcolor = \"black\",\n\t\tfill = \"gray\"\n\t) +\n\tggplot2::facet_wrap(ggplot2::vars(name)) +\n\tggplot2::scale_x_continuous(\n\t\tbreaks = seq(0, 1, 0.1),\n\t\tminor_breaks = seq(0, 1, 0.05),\n\t\tlabels = seq(0, 1, 0.1),\n\t\tlimits = c(0, 1)\n\t)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nHere we only do 199 resamples because the program I wrote is super inefficient\nand doing much more would take a while. (Although it is worthwhile to note\nthat the calculation of bootstrap statistics is trivially parallelizable, so\nwith access to sufficient resources, even a computationally expensive statistic \ncan be computed in a reasonable amount of time.)\n\nSo now that we have calculated a bootstrap distribution for our statistic of\ninterest (the VE, along with its component statistics as recordkeeping), how\ndo we estimate the CI from this distribution? In my opinion, the most\nintuitive way is to use the percentile method.\n\n## Percentile method\n\nBefore introducing the percentile method, we should note that many people on\nthe internet will complain and moan about how \"bad\" this method is, including\nDavison and Hinkley (who did it in their book that is older than stack\nexchange or whatever). People like to moan about how it is not quite right,\nbut as Efron (bootstrap inventor and expert) and Hastie put it, the goal of\nbootstraps is to have wide applicability and close to perfect coverage. So\nthis method is, in general, pretty good in a wide variety of cases. Especially\nif we think about all the errors that get compounded in the process of observing\nand analyzing real-world data, something as trivial as being a few coverage\npercentage points off from $95\\%$ is really not something to cry about,\nespecially when we can construct intervals for arbitrarily complicated\nstatistics. So, let's define the method.\n\nThe percentile method indeed is so simple that skepticism is natural. Whereas\nother bootstrap methods rely on finding normalization transformations to ensure\ncorrect confidence limits, the percentile method relies only on the existence\nof such a transformation, which can be unknown to us, as this method is\n*scale-invariant.* This method literally just involves calculating the closest\nempirical quantiles of interest to those we are interested in. Using the\npercentile method, a $95\\%$ confidence interval for the VE would be\n$$\\left( \\mathrm{VE}^{*}_{(B+1)(0.025)}, \\mathrm{VE}^{*}_{(B+1)(0.975)} \\right)$$\n\nSo if we chose $B=199$, then we would order our observed statistics, and our\npercentile method CI would be formed by the 5th entry in that vector and the\n195th entry in that vector. For such ease of computation, $B = 399$ or $599$\nand so on are often used to ensure the quantiles are exact. However, again,\nthis is an example of sweating over tiny amounts of CI coverage that likely are\nnot too important to begin with, so choosing a nice round number like $B = 2000$\nis often sufficient. Typically, you need at least $B = 1000$, though $B = 10000$\n(or $9999\\ldots$) is even better and typically not even too computationally\ndemanding on modern machines. So, for our example, our percentile CI for\nthe VE would be calculated as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsort(res$VE)[c(5, 195)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4441367 0.9032258\n```\n:::\n:::\n\n\nR has a lot of quantile algorithms, but we can specifically use Type 1 or 2 to\nget the same estimates (2 is probably better if you don't use a $B$ ending in \n9's). The others are all fairly similar though and like I\nsaid, I really don't think being upset about the amount of difference you\nget between quantile algorithms really matters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(res$VE, probs = c(0.025, 0.975), type = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     2.5%     97.5% \n0.4441367 0.9032258 \n```\n:::\n:::\n\n\nSo, we would pair this with our empirical estimate of the VE (we could take,\ne.g. the mean of the bootstraps, which should always be similar to the\noverall estimate we already got) to get an estimated VE of\n$$\\widehat{VE} = 69.57\\% \\ \\left(95\\% \\text{ CI: } 44.41\\% \\ - \\ 90.32\\%\\right).$$\nNow that is maybe not the most precise estimate of VE in the world, but based\non the bootstrap percentile method, it at least seems that our vaccine is\nconferring some protection, with the possibility of a pretty good amount. Note\nthat we would expect this CI to get smaller as $n$ increases, but not as $B$\nincreases (this is true of all bootstrap CIs).\n\nOf course, like I said, some people really don't like the percentile method. So\nwe can instead appeal to a much more complicated method devised by Efron and\nsome coworkers called the BCa method, and I'll show how to automate the\ncalculation of these CIs.\n\n## BCa method and `boot`\n\nThe bias-corrected and accelerated (BCa) percentile method introduces, as you\nmight guess, new complications to reduce the bias and accelerate the\nconvergence of the percentile bootstrap method. Davison and Hinkley agree with Efron and Hastie that this method fixes many of the issues with\nthe basic percentile CI, and there are not really any major objections in the\nsame way that there are for the percentile method. However, this method can\nbe more computationally intensive and certainly more demanding to calculate,\nand as such I do not recommend implementing in by hand in everyday situations.\nThe central problem here is the estimation of the acceleration parameter $a$,\nalthough there is fortunately a nonparametric estimator that works well in\nmany situations.\n\nSo, we will use the `boot` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(boot)\n```\n:::\n\n\nThe first step to getting bootstrap CIs via `boot` is to write a function\nwith a specific order of arguments. The first argument passed to this\nfunction will be the original data, and the second will be a vector of indices\nwhich are sampled by the bootstrapping procedure. Additional arguments are\nallowed. For our problem, a function might look like this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nest_VE <- function(data, idx) {\n\t# Sample the data indices that we should use for this sample\n\tD_i <- data[idx, ]\n\t# Code to calculate the risk in the placebo group and the risk in the\n\t# treatment group\n\tp_p <- mean(subset(D_i, treatment == 0)$outcome)\n\tp_t <- mean(subset(D_i, treatment == 1)$outcome)\n\tRR <- p_t / p_p\n\t\n\t# Return the VE\n\treturn(1 - RR)\n}\n```\n:::\n\n\nNext, we need to create a resampling object using the `boot::boot()` function.\nI'll comment the important arguments in the code chunk. There are many other\narguments we could pass in, and the details of those are described in the\nmanual or in Davison and Hinkley (see references). In particular, the\n`parallel`, `cl`, and `ncpus` arguments can be used for easy parallel computing.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(7071234)\nVE_boot <- boot::boot(\n\t# First argument is the data frame\n\tdata = sim_dat,\n\t# Second argument is the function we want to calculate on resamples\n\tstatistic = est_VE,\n\t# R is the number of resamples, which I called B before\n\tR = 9999,\n\t# We want to use ordinary nonparametric bootstrap -- this is the default\n\t# but I wanted to emphasize it\n\tsim = \"ordinary\"\n)\n```\n:::\n\n\nBecause the `boot` package is optimized so well, that seems like it actually\ntook less time than my simple example earlier. If we just print the object,\nwe can see the estimated statistic and bootstrap SE.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nVE_boot\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot::boot(data = sim_dat, statistic = est_VE, R = 9999, sim = \"ordinary\")\n\n\nBootstrap Statistics :\n     original     bias    std. error\nt1* 0.6956522 -0.0074171   0.1223473\n```\n:::\n:::\n\n\nWe can also plot the bootstrap distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(VE_boot)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nWe can see that it is nonnormal, with a long left tail. Such nonnormality\nindicates that the normal approximate bootstrap method (which I didn't discuss)\nis not appropriate, and the BCa method is generally much better in this case.\n\nThere is a lot you can do with this package that I am not going to talk about\nand don't really know about. But the next thing we want to do for this\nexample is compute those BCa confidence intervals. Fortunately for us, we\ncan actually calculate all the types of CI available with one function call.\nNote that we could also compute the \"studentized\" CI, but that requires us to\nspecify variances for each observation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nVE_ci <- boot::boot.ci(\n\tVE_boot, conf = 0.95,\n\ttype = c(\"norm\", \"basic\", \"perc\", \"bca\")\n)\nVE_ci\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 9999 bootstrap replicates\n\nCALL : \nboot::boot.ci(boot.out = VE_boot, conf = 0.95, type = c(\"norm\", \n    \"basic\", \"perc\", \"bca\"))\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 0.4633,  0.9429 )   ( 0.4991,  0.9807 )  \n\nLevel     Percentile            BCa          \n95%   ( 0.4106,  0.8922 )   ( 0.3701,  0.8778 )  \nCalculations and Intervals on Original Scale\n```\n:::\n:::\n\n\nWe can see that the percentile CI is quite similar to the one we got by hand,\nwhich is nice and the difference is likely attributable to random error.\nNotice, however, that the normal and basic intervals are shifted upwards from\nthe percentile interval, and the BCa interval is shifted down. The BCa interval\nis corrected for bias, which is why it is shifted down (in Efron and Hastie\nthey discuss why our CIs might be biased upwards to begin with). In this case,\nthe different intervals are actually a bit different, although again I'm not\nsure how useful it is to fret over whether the lower limit of the CI for our\nVE is $41\\%$ or $37\\%$. (But I do admit that a range of $46\\%$ to $37\\%$ across\nmethods is not ideal, though I don't know that these two estimates would change \nany qualitative decisions that you might make based on the analysis. But either\nway the normal method is not great, and I don't love the basic method, which\nis why I didn't recommend using either of those.)\nIn general I would use the BCa limits, since\nthey are the least controversial, technically the \"best\" in a specific sense,\nand are just as easy to calculate.\n\n## Conclusions\n\nIn this tutorial, we simulated data and got confidence intervals using two\ndifferent bootstrap methods for the VE from a theoretical vaccine study. We\ndemonstrated how easy it is to obtain BCa intervals using the `boot` package in\n`R`.\n\nWe should note that bootstrapping does not solve any issues induced by having\ntoo low of a sample size -- bootstrap CIs will often be just as bad as any\nother CIs if the sample size is quite small. If I were to keep writing this\nblog post, I would compute several of the other alternative CIs for the VE,\nlike the normal approximate and whatever exact CIs people are using for that\nright now, I just couldn't think of those off the top of my head and I don't\nthink comparing to only the normal approximate CI is useful.\n\nThere are some limitations to bootstrap, especially when we start using complex\nhierarchical models. But for simple CI calculations, nonparametric BCa\nbootstraps can often provide a decent CI estimate without requiring any\nanalytical derivations.\n\n## References\n\n> Davison AC and Hinkley DV. Bootstrap Methods and their Applications, 1997.\nCambridge University Press, Cambridge. ISBN 0-521-57391-2.\n> Efron B and Hastie T. Computer Age Statistical Inference, student edition, 2021. Cambridge University Press, Cambridge.\n> Rousselet GA, Pernet CR, Wilcox RR. The Percentile Bootstrap: A Primer With Step-by-Step Instructions in R. Advances in Methods and Practices in Psychological Science. 2021;4(1). doi:10.1177/2515245920911881.\n> Angelo Canty and Brian Ripley (2022). boot: Bootstrap R (S-Plus) Functions. R package version 1.3-28.1.\n\n## Details {.appendix}\n\nLast updated at 2023-10-09 20:44:27.346987.\n\n[source code](https://github.com/wzbillings/zlog/tree/master/_posts/posts/2023-10-09_BootstrapIntro/index.qmd)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.3.1 (2023-06-16 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19044)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n[1] boot_1.3-28.1 ggplot2_3.3.6\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.1      jsonlite_1.8.3    dplyr_1.0.10      compiler_4.3.1   \n [5] renv_0.16.0       tidyselect_1.2.0  stringr_1.4.1     tidyr_1.2.1      \n [9] scales_1.2.1      yaml_2.3.6        fastmap_1.1.0     R6_2.5.1         \n[13] labeling_0.4.2    generics_0.1.3    knitr_1.40        htmlwidgets_1.5.4\n[17] tibble_3.1.8      munsell_0.5.0     pillar_1.8.1      rlang_1.0.6      \n[21] utf8_1.2.2        stringi_1.7.8     xfun_0.34         cli_3.4.1        \n[25] withr_2.5.0       magrittr_2.0.3    digest_0.6.30     grid_4.3.1       \n[29] lifecycle_1.0.3   vctrs_0.5.0       evaluate_0.17     glue_1.6.2       \n[33] farver_2.1.1      fansi_1.0.3       colorspace_2.0-3  rmarkdown_2.17   \n[37] purrr_0.3.5       tools_4.3.1       pkgconfig_2.0.3   ellipsis_0.3.2   \n[41] htmltools_0.5.3  \n```\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}